(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{572:function(e,t,a){"use strict";a.r(t);var r=a(19),s=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h2",{attrs:{id:"webrtc目录结构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#webrtc目录结构"}},[e._v("#")]),e._v(" WebRTC目录结构")]),e._v(" "),a("p",[e._v("主目录结构：")]),e._v(" "),a("p",[a("img",{staticClass:"lazy",attrs:{alt:"image","data-src":"https://cdn.jsdelivr.net/gh/jonsam-ng/image-hosting@master/20220628/image.7i31hkemglo0.webp",loading:"lazy"}})]),e._v(" "),a("ul",[a("li",[e._v("api目录：如果我们要增加接口或者调整接口，就需要到API目录下去修改相关接口。")]),e._v(" "),a("li",[e._v("call目录：当与对端进行连接之后，同一个端的流通过Call进行管理;如果与多个对端进行连接，就会存在多个Call。")]),e._v(" "),a("li",[e._v("media目录：内部实现了编解码的逻辑处理（并没有实现编解码内部逻辑，是在Module中实现的），只是对编解码算法进行了调用控制（决定在哪调用）。")]),e._v(" "),a("li",[e._v("module目录：有很多子模块。")]),e._v(" "),a("li",[e._v("pc目录：代表与对端的连接，可以获取流，获取统计信息（上层的统一接口层）。")])]),e._v(" "),a("p",[e._v("Module目录：")]),e._v(" "),a("p",[a("img",{staticClass:"lazy",attrs:{alt:"image","data-src":"https://cdn.jsdelivr.net/gh/jonsam-ng/image-hosting@master/20220628/image.6bzohofusjc0.webp",loading:"lazy"}})]),e._v(" "),a("ul",[a("li",[e._v("audio_mixer目录：实现混音操作，比如在多人通话时候，需要对多个音频进行混合处理，这样在传输时比较方便，减少了音频流。")]),e._v(" "),a("li",[e._v("audio_processing目录：实现音频的前后处理，比如降噪、回音消除...")]),e._v(" "),a("li",[e._v("video_processing目录：实现视频的前后处理，可以添加如人脸识别等操作...")])]),e._v(" "),a("h2",{attrs:{id:"参考"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[e._v("#")]),e._v(" 参考")]),e._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/egege/webrtc-src",target:"_blank",rel:"noopener noreferrer"}},[e._v("egege/webrtc-src: Mirror of WebRTC(https://webrtc.googlesource.com/src)"),a("OutboundLink")],1)]),e._v(" "),a("li",[a("a",{attrs:{href:"https://webrtc.googlesource.com/src",target:"_blank",rel:"noopener noreferrer"}},[e._v("webrtc - Git at Google"),a("OutboundLink")],1)])])])}),[],!1,null,null,null);t.default=s.exports}}]);